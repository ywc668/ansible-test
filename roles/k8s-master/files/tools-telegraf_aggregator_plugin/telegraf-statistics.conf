# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf-differentiate.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply prepend
# them with $. For strings the variable must be within quotes (ie, "$STR_VAR"),
# for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "5s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at
  ## most metric_batch_size metrics.
  metric_batch_size = 1000
  ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
  ## output, and will flush this buffer on a successful write. Oldest metrics
  ## are dropped first when this buffer fills.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. You shouldn't set this below
  ## interval. Maximum flush_interval will be flush_interval + flush_jitter
  flush_interval = "5s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default, precision will be set to the same timestamp order as the
  ## collection interval, with the maximum being 1s.
  ## Precision will NOT be used for service inputs, such as logparser and statsd.
  ## Valid values are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""
  ## Run telegraf in debug mode
  debug = false
  ## Run telegraf in quiet mode
  quiet = false
  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false


###############################################################################
#                            Aggregators PLUGINS                                   #
###############################################################################
[[aggregators.statistics]]
  drop_original = true
  period = "8s"
  ## Should it forward not-defined tables?
  Forward_other_measurements = true
  ## define the aggregation policy for each measurement/table
  [aggregators.statistics.measurements]
    [aggregators.statistics.measurements.metrics_app48]
      Keep_incalculable_fields = true
      Statistics_values = ["mean","max"]
      Expand_single_metric = true
    [aggregators.statistics.measurements.metrics_app48.truncate_tags]
      "io.kubernetes.pod.name" = "(.*?)-.*"  # use pod name before dash, eg.  pod-abc-1234    ===>  pod

  ## define the index server
  [aggregators.statistics.indexer]
    Redis_Address = "redis.autoshift:6379"
    Redis_Password = ""
    Redis_DB = 0
    Indexed_table_name = "ABT_metrics_app48"
    All_values_in_float64 = true
    Duration_of_each_row = "2s"
    N_row_in_cache = 6
###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################
## Files to write to, "stdout" is a specially handled file.
# [[outputs.file]]
#  files = ["stdout", "/tmp/metrics.out"]
#  ## Data format to output.
#  ## Each data format has it's own unique set of configuration options, read
#  ## more about them here:
#  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
#  data_format = "influx"

[[outputs.influxdb]]
  ## The full HTTP or UDP endpoint URL for your InfluxDB instance.
  ## Multiple urls can be specified as part of the same cluster,
  ## this means that only ONE of the urls will be written to each interval.
  # urls = ["udp://localhost:8089"] # UDP endpoint example
  # urls = ["http://localhost:8086"] # UDP endpoint example
  # urls = ["http://192.168.1.16:8086"] # required
  urls = ["http://influxdb.autoshift:8086"] # required
  ## The target database for metrics (telegraf will create it if not exists).
  database = "user_1" # globally unique, replace "app" with name+app_id

  ## Retention policy to write to. Empty string writes to the default rp.
  # retention_policy = ""
  ## Write consistency (clusters only), can be: "any", "one", "quorum", "all"
  # write_consistency = "any"

  ## Write timeout (for the InfluxDB client), formatted as a string.
  ## If not provided, will default to 5s. 0s means no timeout (not recommended).
  # timeout = "5s"
  # username = "autoshift"
  # password = "inflx4autoshift"
  ## Set the user agent for HTTP POSTs (can be useful for log differentiation)
  # user_agent = "telegraf"
  ## Set UDP payload size, defaults to InfluxDB UDP Client default (512 bytes)
  # udp_payload = 512

  ## Optional SSL Config
  # ssl_ca = "/etc/telegraf/ca.pem"
  # ssl_cert = "/etc/telegraf/cert.pem"
  # ssl_key = "/etc/telegraf/key.pem"
  ## Use SSL but skip chain & host verification
  # insecure_skip_verify = false

  # Configuration for the Kafka server to send metrics to
[[outputs.kafka]]
  ## URLs of kafka brokers
  brokers = ["10.185.190.51:9092"]
  ## Kafka topic for producer messages
  topic = "ABT_metrics_app48"   # the analytic based table of the application, replace "app" with name+app_id
  ## Telegraf tag to use as a routing key
  ##  ie, if this tag exists, it's value will be used as the routing key
  # routing_tag = "host"

  ## Optional SSL Config
  # ssl_ca = "/etc/telegraf/ca.pem"
  # ssl_cert = "/etc/telegraf/cert.pem"
  # ssl_key = "/etc/telegraf/key.pem"
  ## Use SSL but skip chain & host verification
  # insecure_skip_verify = false

  ## Data format to output. This can be "influx" or "graphite"
  ## Each data format has it's own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
  data_format = "influx"

###############################################################################
#                            INPUT PLUGINS                                   #
###############################################################################
# Read metrics from Kafka topic(s)
[[inputs.kafka_consumer]]
  ## topic(s) to consume
  topics = ["raw_metrics_app48"] # replace "app" with name+app_id
  ## an array of Zookeeper connection strings
  zookeeper_peers = ["10.185.190.51:2181"]
  ## the name of the consumer group
  consumer_group = "48"
  ## Maximum number of metrics to buffer between collection intervals
  metric_buffer = 100000
  ## Offset (must be either "oldest" or "newest")
  offset = "newest"

  ## Filter unwanted tags
  tagexclude = ["host"]

  ## Data format to consume.

  ## Each data format has it's own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
  data_format = "influx"

  [inputs.kafka_consumer.tagdrop]
    "io.kubernetes.container.name"=["POD"]
